{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12676,"status":"ok","timestamp":1724251769226,"user":{"displayName":"Ramakrishna Perla","userId":"14162718140622650242"},"user_tz":-330},"id":"wD3tj_EwIsil","outputId":"4891340d-cf3e-4218-b138-036db0fde9f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rarfile\n","  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n","Downloading rarfile-4.2-py3-none-any.whl (29 kB)\n","Installing collected packages: rarfile\n","Successfully installed rarfile-4.2\n"]}],"source":["pip install rarfile"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34670,"status":"ok","timestamp":1724251803894,"user":{"displayName":"Ramakrishna Perla","userId":"14162718140622650242"},"user_tz":-330},"id":"SPQimzpfIeuf","outputId":"7177fb4a-74c8-4104-b9c5-06dbd311f9e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Importing necessary libraries\n","import pandas as pd\n","import numpy as np\n","import os\n","import rarfile\n","import cv2\n","from google.colab import drive\n","import pickle\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from time import sleep\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.regularizers import l2\n","\n","from tensorflow.keras.layers import Conv1D,Reshape, MaxPooling1D, Flatten, Dense, Conv2D,LSTM, MaxPooling2D,Dropout\n","from tensorflow.keras import backend as K\n","\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from PIL import Image\n","from tqdm.notebook import tqdm\n","import io\n","\n","\n","# mounting drive\n","drive.mount('/content/drive')\n","data_path = '/content/drive/MyDrive/Assignments/emotion_recognition_clip/dataset_zips'\n","\n","\n"]},{"cell_type":"code","source":["def mean_absolute_deviation(y_true, y_pred):\n","    \"\"\"\n","    Compute the Mean Absolute Deviation (MAD) between true and predicted values.\n","\n","    Parameters:\n","    y_true (tensor): True labels.\n","    y_pred (tensor): Predicted values.\n","\n","    Returns:\n","    tensor: The MAD metric.\n","    \"\"\"\n","    return 1 - K.mean(K.abs(y_pred - y_true), axis=-1)"],"metadata":{"id":"qFKFVLr7BCQX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# required input files to run the notebook\n","# train_image_names.npy, test_image_names.npy, train_image_embeds.rar"],"metadata":{"id":"O_JXKk1L41Dg"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1217,"status":"ok","timestamp":1724251805107,"user":{"displayName":"Ramakrishna Perla","userId":"14162718140622650242"},"user_tz":-330},"id":"tM8fnY342AZz","outputId":"579739a7-b34b-4ddb-e97e-fa300cc58b53"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(20000,)"]},"metadata":{},"execution_count":5}],"source":["# extracting image index for train and test datasets\n","file_names = np.load(os.path.join(data_path,'train_image_names.npy'))\n","file_names_test = np.load(os.path.join(data_path,'test_image_names.npy'))\n","file_names_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Vlwb4pikZ1q"},"outputs":[],"source":["# extracting image embeddings from CLIP ViT-L/14 model(.pt pytorch files)\n","rarfile_path = os.path.join(data_path, 'train_image_embeds.rar')\n","train_images_rar = rarfile.RarFile(rarfile_path)\n","train_feat_files = train_images_rar.infolist()\n","train_feat_files = [x.filename for x in train_feat_files]\n","\n","# extracting image embeddings from CLIP ViT-L/14 model(.pt pytorch files test)\n","rarfile_path_test = os.path.join(data_path, 'FEATURES_TEST')\n","list_files_test = os.listdir(rarfile_path_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":117,"referenced_widgets":["7dca3359b4f643588dae84bddd3b3317","ac59759f851a497abac162bc8c66eb20","b930956c9b554687a23fe735e6517e2d","18a6870a37ca42a8a0acafc895ebf095","7f5f85da853c4fc3b21e38fc53d58bc8","8011d68b1e504a958e01b1199e2c7dc5","c22012026fa04f438c7dc79809f983f8","b18ec9819cfa4b4d82e576cb00cc2354","2b18b5d7f7214ba3a733957da1f767bb","152f05a8b5dc49eaa199586508333512","3b519d4e34ca4997983c7f11eabd51ae","72ae9cd15d744d4db1c6c2f869114bbf","a5a37f64df7f4648a75996703e514359","61e6e2e2e1c14e6d9498f09b63d97c1e","113001b09f5c4e5fa5ec7ee8069793d4","b01b4ebf918048e89ab0f876ced2cb52","58efc092771749fa866cb034998dd1bc","04e1428161c64142929186bf8d4d7acd","9c4898d534194f2f9535569eb3416833","84afd341550e48fb80de3dffdb827246","57836dcd081a4a12a109f33f02b52479","1574f7c5ac76492ab2ce559f4ae229cf"]},"executionInfo":{"elapsed":26782,"status":"ok","timestamp":1724251833097,"user":{"displayName":"Ramakrishna Perla","userId":"14162718140622650242"},"user_tz":-330},"id":"qdzRZ2TDrHm_","outputId":"d7889071-cda2-4c9d-f870-9954be990f23"},"outputs":[{"output_type":"stream","name":"stdout","text":[" Reading image embed files Train\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/362 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dca3359b4f643588dae84bddd3b3317"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Reading image embed files Test\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/200 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72ae9cd15d744d4db1c6c2f869114bbf"}},"metadata":{}}],"source":["print(\" Reading image embed files Train\")\n","all_files = []\n","for file_ in tqdm(range(len(train_feat_files)-1)):\n","    file_name = 'train_image_embeds/feat_image_batch_{}.pt'.format(file_)\n","    if file_name.endswith('.pt'):\n","      image_feat = train_images_rar.read(file_name)\n","      image_feat =  torch.load(io.BytesIO(image_feat))\n","      all_files.append(image_feat)\n","    else:\n","      print (file_.filename)\n","\n","print(\" Reading image embed files Test\")\n","all_files_test = []\n","for file_ in tqdm(range(len(list_files_test))):\n","    file_name = 'feat_image_batch_{}.pt'.format(file_)\n","    if file_name.endswith('.pt'):\n","      image_feat =  torch.load(os.path.join(rarfile_path_test, file_name))\n","\n","      all_files_test.append(image_feat)\n","\n","\n","\n","#concatinating all image features\n","all_torch = torch.cat(all_files)\n","all_torch_test = torch.cat(all_files_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fkOamihNsNYH"},"outputs":[],"source":["#extraciting every 10th frame name for video index and removing \"frame_\" for train\n","all_torch_index = file_names[:all_torch.shape[0]:10]\n","index_names = [x.split('_frame')[0].replace('_','') for x in all_torch_index]\n","\n","#extraciting every 10th frame name for video index and removing \"frame_\" for train\n","all_torch_index_test = file_names_test[:all_torch_test.shape[0]:10]\n","index_names_test = [x.split('_frame')[0].replace('_','') for x in all_torch_index_test]\n","\n","\n","##flattening data and reshaping it to required format for LSTM (no of inputs, timeframes, feature size)\n","flatten_torch = all_torch.flatten()\n","reshape_torch = flatten_torch.reshape((int(all_torch.shape[0]/10), 10,768))\n","\n","flatten_torch_test = all_torch_test.flatten()\n","reshape_torch_test = flatten_torch_test.reshape((int(all_torch_test.shape[0]/10), 10,768))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MBu-O2l3Jpp2"},"outputs":[],"source":["# reading ground truth annotations for train and test and changing it to pandas format for easier processing\n","annotations_train = pd.read_pickle(os.path.join(data_path, 'annotation_training.pkl'))\n","annotations_test = pd.read_pickle(os.path.join(data_path, 'annotation_test.pkl'))\n","classify_labels = list(annotations_test.keys()) # capturing output classes\n","ground_truth = pd.DataFrame(annotations_test).reset_index()\n","ground_truth['image_name'] = ground_truth['index'].map(lambda x: '.'.join(x.split('.')[:-1]))\n","ground_truth['image_name'] = ground_truth['image_name'].map(lambda x: x.replace('_',''))\n","ground_truth = ground_truth.drop(['index'], axis = 1)\n","ground_truth = ground_truth.set_index(['image_name'])\n","ground_truth = ground_truth.loc[index_names_test].drop([\"interview\"],axis = 1)\n","\n","\n","ground_truth_train = pd.DataFrame(annotations_train).reset_index()\n","ground_truth_train['image_name'] = ground_truth_train['index'].map(lambda x: '.'.join(x.split('.')[:-1]))\n","ground_truth_train['image_name'] = ground_truth_train['image_name'].map(lambda x: x.replace('_',''))\n","ground_truth_train = ground_truth_train.drop(['index'], axis = 1)\n","ground_truth_train = ground_truth_train.set_index(['image_name'])\n","ground_truth_train = ground_truth_train.loc[index_names].drop([\"interview\"],axis =1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eiqspy3S2lVK"},"outputs":[],"source":["# converting inputs to numpy arrrays for pytorch model input\n","y_train = ground_truth_train.to_numpy()\n","X_train = reshape_torch.numpy()\n","y_test = ground_truth.to_numpy()\n","X_test = reshape_torch_test.numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1724251834209,"user":{"displayName":"Ramakrishna Perla","userId":"14162718140622650242"},"user_tz":-330},"id":"xvKSm54U9Cgh","outputId":"c994956a-6a53-41f6-bc2a-f4dd3bf1f950"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((3620, 10, 768), (3620, 5), (2000, 10, 768), (2000, 5))"]},"metadata":{},"execution_count":11}],"source":["# X_train = (X_train - X_train.mean())/X_train.std()\n","# X_test = (X_test - X_train.mean())/X_train.std()\n","\n","X_train.shape, y_train.shape, X_test.shape, y_test.shape"]},{"cell_type":"code","source":["def metrics_calc(pred, act):\n","    print ('*'*100)\n","    print('Evaluating mean accuracy on test data \\n')\n","    acc = []\n","    # calculating mean accuracy for each trait\n","    for column in pred:\n","        # print (column)\n","        # acc_class = 1 - ((abs(pred[column] - act[column])).mean()/abs(act[column] - act[column].mean()).sum())\n","        acc_class = 1 - ((abs(pred[column] - act[column])).mean())\n","        print ('accuracy for {} is {}'.format(column, acc_class))\n","        acc.append(acc_class)\n","    print (\"mean accuracy for all classes {}\".format(np.mean(acc)))\n","\n","def estimate_accuracy(predictions_model, actuals= ground_truth, column_names = list(annotations_test.keys())[:4] +[list(annotations_test.keys())[-1]], audio_test_names = index_names_test):\n","    test_names = [x for x in audio_test_names]\n","    predictions = pd.DataFrame(predictions_model, columns =column_names, index = test_names)\n","    predictions = predictions.reset_index()\n","    predictions['image_name'] = predictions['index'].map(lambda x: x) # removing frame number to get only the image name\n","    predictions = predictions.drop(['index'], axis = 1)\n","    predictions = predictions.groupby(['image_name']).mean() # average score at image level (grouping all frames result into single result)\n","    metrics_calc(predictions.sort_index(), actuals.sort_index())"],"metadata":{"id":"oK9zQVtODoak"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Feed Forward Neural Network"],"metadata":{"id":"smLbkPGEMn0M"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1DQ8wu0AgE1A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724251864939,"user_tz":-330,"elapsed":14048,"user":{"displayName":"Ramakrishna Perla","userId":"14162718140622650242"}},"outputId":"6a709914-fb61-409c-9b35-fe225885ebdc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - loss: 0.1007 - mean_absolute_deviation: 0.7358 - val_loss: 0.0528 - val_mean_absolute_deviation: 0.8297\n","Epoch 2/10\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0351 - mean_absolute_deviation: 0.8628 - val_loss: 0.0156 - val_mean_absolute_deviation: 0.9004\n","Epoch 3/10\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0127 - mean_absolute_deviation: 0.9104 - val_loss: 0.0148 - val_mean_absolute_deviation: 0.9033\n","Epoch 4/10\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0106 - mean_absolute_deviation: 0.9180 - val_loss: 0.0141 - val_mean_absolute_deviation: 0.9053\n","Epoch 5/10\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0101 - mean_absolute_deviation: 0.9199 - val_loss: 0.0139 - val_mean_absolute_deviation: 0.9062\n","Epoch 6/10\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0092 - mean_absolute_deviation: 0.9233 - val_loss: 0.0138 - val_mean_absolute_deviation: 0.9068\n","Epoch 7/10\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0087 - mean_absolute_deviation: 0.9259 - val_loss: 0.0139 - val_mean_absolute_deviation: 0.9060\n","Epoch 8/10\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0082 - mean_absolute_deviation: 0.9283 - val_loss: 0.0139 - val_mean_absolute_deviation: 0.9060\n","Epoch 9/10\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0078 - mean_absolute_deviation: 0.9300 - val_loss: 0.0146 - val_mean_absolute_deviation: 0.9045\n","Epoch 10/10\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0075 - mean_absolute_deviation: 0.9312 - val_loss: 0.0143 - val_mean_absolute_deviation: 0.9048\n","printing predicion accuracy for trained model\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","****************************************************************************************************\n","Evaluating mean accuracy on test data \n","\n","accuracy for extraversion is 0.910902754912971\n","accuracy for neuroticism is 0.9042274779379368\n","accuracy for agreeableness is 0.9074275122997197\n","accuracy for conscientiousness is 0.9144907872389676\n","accuracy for openness is 0.9094179938332903\n","mean accuracy for all classes 0.9092933052445771\n"]}],"source":["def build_model(input_shape, num_classes):\n","    \"\"\"\n","    base model, flattening data and passing it to dense layer\n","    \"\"\"\n","    model = Sequential()\n","    model.add(Flatten())\n","\n","    # Dense layers\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dense(num_classes, activation='sigmoid'))  # Sigmoid for multi-label classification\n","\n","    return model\n","\n","num_classes = y_train.shape[1]  # Number of labels\n","\n","model = build_model((10, 768), num_classes)\n","model.compile(\n","    optimizer=Adam(),\n","    loss='mse',  # Binary cross-entropy for multi-label classification\n","    metrics=[mean_absolute_deviation]\n",")\n","# Train the model\n","\n","history = model.fit(\n","    X_train, y_train,\n","    epochs=10,  # Number of epochs\n","    batch_size=128,  # Batch size\n","    validation_split=0.1  # Split data for validation\n",")\n","\n","print(\"printing predicion accuracy for trained model\")\n","y_predict =model.predict(X_test)\n","\n","estimate_accuracy(y_predict)"]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"id":"vekjDVjAZ5Mg","executionInfo":{"status":"ok","timestamp":1724083841193,"user_tz":-330,"elapsed":6,"user":{"displayName":"Ramakrishna Perla","userId":"14162718140622650242"}},"outputId":"96c958fc-ef6b-4fa8-e972-2fbb96575537"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7680\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m983,168\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m645\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7680</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">983,168</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,951,441\u001b[0m (11.26 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,951,441</span> (11.26 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m983,813\u001b[0m (3.75 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">983,813</span> (3.75 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,967,628\u001b[0m (7.51 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,967,628</span> (7.51 MB)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["# LSTM Model"],"metadata":{"id":"4UVZoXhVcPQ4"}},{"cell_type":"code","source":["import tensorflow as tf\n","# from tensorflow.keras.models import Sequential\n","# from tensorflow.keras.layers import LSTM, Dense, Dropout\n","\n","# Define the model\n","model = Sequential()\n","\n","# LSTM Layer\n","model.add(LSTM(128, input_shape=(10, 768), return_sequences=False))  # You can adjust units\n","\n","# Dropout for regularization\n","model.add(Dropout(0.3))\n","\n","# Fully connected layer\n","model.add(Dense(64, activation='relu'))\n","\n","# Output layer with 5 outputs for class probabilities\n","model.add(Dense(5, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n","\n","# Model Summary\n","model.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"id":"V5OavsvqbI9H","executionInfo":{"status":"ok","timestamp":1724084176865,"user_tz":-330,"elapsed":445,"user":{"displayName":"Ramakrishna Perla","userId":"14162718140622650242"}},"outputId":"6d2e28ee-d2c0-4bf6-8c7c-c70a862e54cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_2\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m459,264\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m325\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">459,264</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m467,845\u001b[0m (1.78 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">467,845</span> (1.78 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m467,845\u001b[0m (1.78 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">467,845</span> (1.78 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["history = model.fit(X_train, y_train,\n","                    epochs=50,\n","                    batch_size=32,\n","                    validation_split=0.2,\n","                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dZpyuGDabP5b","executionInfo":{"status":"ok","timestamp":1724084241449,"user_tz":-330,"elapsed":49142,"user":{"displayName":"Ramakrishna Perla","userId":"14162718140622650242"}},"outputId":"b0e5802b-be97-4d66-d5c4-25b7f67aea6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - loss: 0.0186 - mae: 0.1078 - val_loss: 0.0141 - val_mae: 0.0949\n","Epoch 2/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - loss: 0.0116 - mae: 0.0861 - val_loss: 0.0130 - val_mae: 0.0911\n","Epoch 3/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 0.0099 - mae: 0.0795 - val_loss: 0.0128 - val_mae: 0.0901\n","Epoch 4/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - loss: 0.0093 - mae: 0.0773 - val_loss: 0.0129 - val_mae: 0.0910\n","Epoch 5/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - loss: 0.0079 - mae: 0.0709 - val_loss: 0.0130 - val_mae: 0.0914\n","Epoch 6/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0078 - mae: 0.0705 - val_loss: 0.0133 - val_mae: 0.0917\n","Epoch 7/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - loss: 0.0073 - mae: 0.0674 - val_loss: 0.0131 - val_mae: 0.0913\n","Epoch 8/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - loss: 0.0068 - mae: 0.0656 - val_loss: 0.0130 - val_mae: 0.0907\n"]}]},{"cell_type":"code","source":["\n","y_predict =model.predict(X_test)\n","\n","estimate_accuracy(y_predict)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_aE4LTcYbduB","executionInfo":{"status":"ok","timestamp":1724084271781,"user_tz":-330,"elapsed":3312,"user":{"displayName":"Ramakrishna Perla","userId":"14162718140622650242"}},"outputId":"2ddf6bde-e02f-4249-81c6-fb696241241c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n","****************************************************************************************************\n","Evaluating mean accuracy on test data \n","\n","accuracy for extraversion is 0.9115205880604057\n","accuracy for neuroticism is 0.9072131643816829\n","accuracy for agreeableness is 0.9105659773077119\n","accuracy for conscientiousness is 0.919642971279624\n","accuracy for openness is 0.9097282190634145\n","mean accuracy for all classes 0.9117341840185678\n"]}]},{"cell_type":"markdown","source":["# LSTM Model - Experiment 2"],"metadata":{"id":"D-e8b_uNdcZ1"}},{"cell_type":"code","source":["from tensorflow.keras.layers import BatchNormalization\n","lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n"],"metadata":{"id":"EqO3CKU9dC-V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","\n","# First LSTM Layer with Batch Normalization and Dropout\n","model.add(LSTM(128, input_shape=(10, 768), return_sequences=True))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.4))\n","\n","# Second LSTM Layer with Dropout\n","model.add(LSTM(64, return_sequences=False))\n","model.add(Dropout(0.3))\n","\n","# Fully connected layer with L2 regularization\n","model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n","\n","# Output layer with 5 outputs for class probabilities\n","model.add(Dense(5, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='mse', metrics=['mae'])\n","\n","# Train with validation split and learning rate scheduler\n","history = model.fit(X_train, y_train,\n","                    epochs=100,\n","                    batch_size=32,\n","                    validation_split=0.2,\n","                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5),\n","                               lr_scheduler])\n","\n","\n","# Evaluate the model\n","\n","y_predict =model.predict(X_test)\n","\n","estimate_accuracy(y_predict)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N9ppZ4gZcsqw","executionInfo":{"status":"ok","timestamp":1724085065124,"user_tz":-330,"elapsed":382487,"user":{"displayName":"Ramakrishna Perla","userId":"14162718140622650242"}},"outputId":"153effc6-2cbc-42ef-e285-996d63825b81"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 63ms/step - loss: 0.0911 - mae: 0.1364 - val_loss: 0.0789 - val_mae: 0.1151 - learning_rate: 1.0000e-04\n","Epoch 2/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - loss: 0.0776 - mae: 0.1139 - val_loss: 0.0705 - val_mae: 0.1044 - learning_rate: 1.0000e-04\n","Epoch 3/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - loss: 0.0694 - mae: 0.1038 - val_loss: 0.0642 - val_mae: 0.0988 - learning_rate: 1.0000e-04\n","Epoch 4/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - loss: 0.0626 - mae: 0.0975 - val_loss: 0.0592 - val_mae: 0.0967 - learning_rate: 1.0000e-04\n","Epoch 5/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - loss: 0.0573 - mae: 0.0935 - val_loss: 0.0546 - val_mae: 0.0953 - learning_rate: 1.0000e-04\n","Epoch 6/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 65ms/step - loss: 0.0520 - mae: 0.0897 - val_loss: 0.0506 - val_mae: 0.0943 - learning_rate: 1.0000e-04\n","Epoch 7/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 73ms/step - loss: 0.0478 - mae: 0.0878 - val_loss: 0.0470 - val_mae: 0.0939 - learning_rate: 1.0000e-04\n","Epoch 8/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - loss: 0.0437 - mae: 0.0853 - val_loss: 0.0435 - val_mae: 0.0930 - learning_rate: 1.0000e-04\n","Epoch 9/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - loss: 0.0400 - mae: 0.0834 - val_loss: 0.0405 - val_mae: 0.0928 - learning_rate: 1.0000e-04\n","Epoch 10/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - loss: 0.0369 - mae: 0.0822 - val_loss: 0.0377 - val_mae: 0.0924 - learning_rate: 1.0000e-04\n","Epoch 11/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 103ms/step - loss: 0.0334 - mae: 0.0789 - val_loss: 0.0355 - val_mae: 0.0933 - learning_rate: 1.0000e-04\n","Epoch 12/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - loss: 0.0308 - mae: 0.0784 - val_loss: 0.0332 - val_mae: 0.0934 - learning_rate: 1.0000e-04\n","Epoch 13/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.0285 - mae: 0.0775 - val_loss: 0.0312 - val_mae: 0.0933 - learning_rate: 1.0000e-04\n","Epoch 14/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - loss: 0.0264 - mae: 0.0773 - val_loss: 0.0291 - val_mae: 0.0924 - learning_rate: 1.0000e-04\n","Epoch 15/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step - loss: 0.0241 - mae: 0.0754 - val_loss: 0.0278 - val_mae: 0.0936 - learning_rate: 1.0000e-04\n","Epoch 16/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 100ms/step - loss: 0.0222 - mae: 0.0739 - val_loss: 0.0260 - val_mae: 0.0927 - learning_rate: 1.0000e-04\n","Epoch 17/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - loss: 0.0204 - mae: 0.0727 - val_loss: 0.0248 - val_mae: 0.0928 - learning_rate: 1.0000e-04\n","Epoch 18/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - loss: 0.0189 - mae: 0.0717 - val_loss: 0.0238 - val_mae: 0.0940 - learning_rate: 1.0000e-04\n","Epoch 19/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - loss: 0.0178 - mae: 0.0721 - val_loss: 0.0226 - val_mae: 0.0935 - learning_rate: 1.0000e-04\n","Epoch 20/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - loss: 0.0166 - mae: 0.0719 - val_loss: 0.0217 - val_mae: 0.0937 - learning_rate: 1.0000e-04\n","Epoch 21/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step - loss: 0.0153 - mae: 0.0696 - val_loss: 0.0206 - val_mae: 0.0929 - learning_rate: 1.0000e-04\n","Epoch 22/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 65ms/step - loss: 0.0143 - mae: 0.0689 - val_loss: 0.0201 - val_mae: 0.0937 - learning_rate: 1.0000e-04\n","Epoch 23/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - loss: 0.0135 - mae: 0.0689 - val_loss: 0.0193 - val_mae: 0.0937 - learning_rate: 1.0000e-04\n","Epoch 24/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - loss: 0.0128 - mae: 0.0691 - val_loss: 0.0190 - val_mae: 0.0946 - learning_rate: 1.0000e-04\n","Epoch 25/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - loss: 0.0119 - mae: 0.0675 - val_loss: 0.0185 - val_mae: 0.0946 - learning_rate: 1.0000e-04\n","Epoch 26/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 72ms/step - loss: 0.0114 - mae: 0.0675 - val_loss: 0.0183 - val_mae: 0.0950 - learning_rate: 1.0000e-04\n","Epoch 27/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - loss: 0.0107 - mae: 0.0665 - val_loss: 0.0183 - val_mae: 0.0971 - learning_rate: 1.0000e-04\n","Epoch 28/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - loss: 0.0102 - mae: 0.0659 - val_loss: 0.0172 - val_mae: 0.0943 - learning_rate: 1.0000e-04\n","Epoch 29/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 73ms/step - loss: 0.0096 - mae: 0.0646 - val_loss: 0.0169 - val_mae: 0.0944 - learning_rate: 1.0000e-04\n","Epoch 30/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.0093 - mae: 0.0647 - val_loss: 0.0168 - val_mae: 0.0946 - learning_rate: 1.0000e-04\n","Epoch 31/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - loss: 0.0090 - mae: 0.0641 - val_loss: 0.0164 - val_mae: 0.0942 - learning_rate: 1.0000e-04\n","Epoch 32/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - loss: 0.0086 - mae: 0.0637 - val_loss: 0.0160 - val_mae: 0.0939 - learning_rate: 1.0000e-04\n","Epoch 33/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.0084 - mae: 0.0639 - val_loss: 0.0161 - val_mae: 0.0947 - learning_rate: 1.0000e-04\n","Epoch 34/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - loss: 0.0082 - mae: 0.0637 - val_loss: 0.0160 - val_mae: 0.0951 - learning_rate: 1.0000e-04\n","Epoch 35/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 72ms/step - loss: 0.0079 - mae: 0.0628 - val_loss: 0.0159 - val_mae: 0.0947 - learning_rate: 1.0000e-04\n","Epoch 36/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - loss: 0.0078 - mae: 0.0628 - val_loss: 0.0160 - val_mae: 0.0956 - learning_rate: 1.0000e-04\n","Epoch 37/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - loss: 0.0075 - mae: 0.0621 - val_loss: 0.0160 - val_mae: 0.0960 - learning_rate: 1.0000e-04\n","Epoch 38/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - loss: 0.0074 - mae: 0.0624 - val_loss: 0.0156 - val_mae: 0.0955 - learning_rate: 1.0000e-04\n","Epoch 39/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 117ms/step - loss: 0.0071 - mae: 0.0613 - val_loss: 0.0154 - val_mae: 0.0948 - learning_rate: 1.0000e-04\n","Epoch 40/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 79ms/step - loss: 0.0069 - mae: 0.0610 - val_loss: 0.0158 - val_mae: 0.0956 - learning_rate: 1.0000e-04\n","Epoch 41/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - loss: 0.0068 - mae: 0.0603 - val_loss: 0.0156 - val_mae: 0.0957 - learning_rate: 1.0000e-04\n","Epoch 42/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - loss: 0.0067 - mae: 0.0600 - val_loss: 0.0154 - val_mae: 0.0953 - learning_rate: 1.0000e-04\n","Epoch 43/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - loss: 0.0066 - mae: 0.0601 - val_loss: 0.0154 - val_mae: 0.0955 - learning_rate: 5.0000e-05\n","Epoch 44/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - loss: 0.0065 - mae: 0.0593 - val_loss: 0.0154 - val_mae: 0.0955 - learning_rate: 5.0000e-05\n","Epoch 45/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 64ms/step - loss: 0.0066 - mae: 0.0598 - val_loss: 0.0154 - val_mae: 0.0957 - learning_rate: 5.0000e-05\n","Epoch 46/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - loss: 0.0062 - mae: 0.0581 - val_loss: 0.0156 - val_mae: 0.0963 - learning_rate: 2.5000e-05\n","Epoch 47/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - loss: 0.0062 - mae: 0.0581 - val_loss: 0.0157 - val_mae: 0.0965 - learning_rate: 2.5000e-05\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n","****************************************************************************************************\n","Evaluating mean accuracy on test data \n","\n","accuracy for extraversion is 0.9074908177917388\n","accuracy for neuroticism is 0.9017075622826815\n","accuracy for agreeableness is 0.9056389022617714\n","accuracy for conscientiousness is 0.9126070656671541\n","accuracy for openness is 0.9054141950704986\n","mean accuracy for all classes 0.9065717086147689\n"]}]},{"cell_type":"markdown","source":["# CNN Model"],"metadata":{"id":"xRJC6i_jdexq"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout, BatchNormalization\n","\n","# Define the model\n","model = Sequential()\n","\n","# Convolutional Layer 1\n","model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(10, 768)))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.3))\n","\n","# Convolutional Layer 2\n","model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.3))\n","\n","# Flatten the output from the conv layers\n","model.add(Flatten())\n","\n","# Fully connected layer\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.3))\n","\n","# Output layer with 5 outputs for class probabilities\n","model.add(Dense(5, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n","\n","# Model summary\n","model.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":551},"id":"r_dqekkkdIsL","executionInfo":{"status":"ok","timestamp":1724085165239,"user_tz":-330,"elapsed":382,"user":{"displayName":"Ramakrishna Perla","userId":"14162718140622650242"}},"outputId":"3e1cbad6-71a5-45af-d2cd-2c6a6c0102a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_6\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │         \u001b[38;5;34m147,520\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │             \u001b[38;5;34m256\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │          \u001b[38;5;34m24,704\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │             \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m49,216\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m325\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,520</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,216</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m222,533\u001b[0m (869.27 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">222,533</span> (869.27 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m222,149\u001b[0m (867.77 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">222,149</span> (867.77 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["history = model.fit(X_train, y_train,\n","                    epochs=50,\n","                    batch_size=32,\n","                    validation_split=0.2,\n","                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)])\n","\n","\n","# Evaluate the model\n","\n","y_predict =model.predict(X_test)\n","\n","estimate_accuracy(y_predict)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8J-M8zx7e-LF","executionInfo":{"status":"ok","timestamp":1724085232514,"user_tz":-330,"elapsed":46167,"user":{"displayName":"Ramakrishna Perla","userId":"14162718140622650242"}},"outputId":"65350bfc-ba32-4c2d-8518-a02d8c7877e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 0.0826 - mae: 0.2365 - val_loss: 0.0291 - val_mae: 0.1366\n","Epoch 2/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0470 - mae: 0.1736 - val_loss: 0.0197 - val_mae: 0.1113\n","Epoch 3/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0288 - mae: 0.1349 - val_loss: 0.0157 - val_mae: 0.0998\n","Epoch 4/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0203 - mae: 0.1136 - val_loss: 0.0147 - val_mae: 0.0968\n","Epoch 5/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0165 - mae: 0.1025 - val_loss: 0.0146 - val_mae: 0.0965\n","Epoch 6/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0152 - mae: 0.0987 - val_loss: 0.0143 - val_mae: 0.0954\n","Epoch 7/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0135 - mae: 0.0928 - val_loss: 0.0144 - val_mae: 0.0958\n","Epoch 8/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0130 - mae: 0.0910 - val_loss: 0.0143 - val_mae: 0.0956\n","Epoch 9/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0123 - mae: 0.0889 - val_loss: 0.0139 - val_mae: 0.0944\n","Epoch 10/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0122 - mae: 0.0882 - val_loss: 0.0137 - val_mae: 0.0936\n","Epoch 11/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0112 - mae: 0.0847 - val_loss: 0.0135 - val_mae: 0.0928\n","Epoch 12/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0106 - mae: 0.0822 - val_loss: 0.0139 - val_mae: 0.0939\n","Epoch 13/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0107 - mae: 0.0829 - val_loss: 0.0136 - val_mae: 0.0928\n","Epoch 14/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0102 - mae: 0.0807 - val_loss: 0.0136 - val_mae: 0.0931\n","Epoch 15/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0101 - mae: 0.0801 - val_loss: 0.0130 - val_mae: 0.0907\n","Epoch 16/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0101 - mae: 0.0801 - val_loss: 0.0147 - val_mae: 0.0962\n","Epoch 17/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0097 - mae: 0.0786 - val_loss: 0.0136 - val_mae: 0.0924\n","Epoch 18/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0097 - mae: 0.0783 - val_loss: 0.0136 - val_mae: 0.0927\n","Epoch 19/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0093 - mae: 0.0766 - val_loss: 0.0138 - val_mae: 0.0932\n","Epoch 20/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0093 - mae: 0.0769 - val_loss: 0.0141 - val_mae: 0.0945\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n","****************************************************************************************************\n","Evaluating mean accuracy on test data \n","\n","accuracy for extraversion is 0.9084864986845266\n","accuracy for neuroticism is 0.9028089582572381\n","accuracy for agreeableness is 0.9071462223853219\n","accuracy for conscientiousness is 0.9127271686241899\n","accuracy for openness is 0.908309426200721\n","mean accuracy for all classes 0.9078956548303996\n"]}]},{"cell_type":"markdown","source":["# CNN-LSTM Hybrid Model"],"metadata":{"id":"7mAfSQIlfs1b"}},{"cell_type":"code","source":["model = Sequential()\n","\n","# 1D Convolutional Layer to capture local patterns\n","model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(10, 768)))\n","model.add(Dropout(0.3))\n","\n","# LSTM Layer to capture temporal dependencies\n","model.add(LSTM(128, return_sequences=False))\n","model.add(Dropout(0.3))\n","\n","# Fully connected layer\n","model.add(Dense(64, activation='relu'))\n","\n","# Output layer\n","model.add(Dense(5, activation='sigmoid'))\n","\n","# Compile\n","model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n","\n","history = model.fit(X_train, y_train,\n","                    epochs=50,\n","                    batch_size=32,\n","                    validation_split=0.2,\n","                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)])\n","\n","\n","# Evaluate the model\n","\n","y_predict =model.predict(X_test)\n","\n","estimate_accuracy(y_predict)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MtQtAOeCfj_w","executionInfo":{"status":"ok","timestamp":1724085389183,"user_tz":-330,"elapsed":39606,"user":{"displayName":"Ramakrishna Perla","userId":"14162718140622650242"}},"outputId":"244d261f-7833-46a8-8641-9f399494c233"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.0184 - mae: 0.1085 - val_loss: 0.0137 - val_mae: 0.0931\n","Epoch 2/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0126 - mae: 0.0899 - val_loss: 0.0137 - val_mae: 0.0927\n","Epoch 3/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 0.0109 - mae: 0.0825 - val_loss: 0.0137 - val_mae: 0.0925\n","Epoch 4/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 0.0103 - mae: 0.0808 - val_loss: 0.0131 - val_mae: 0.0906\n","Epoch 5/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - loss: 0.0091 - mae: 0.0761 - val_loss: 0.0138 - val_mae: 0.0929\n","Epoch 6/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0087 - mae: 0.0742 - val_loss: 0.0134 - val_mae: 0.0921\n","Epoch 7/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0079 - mae: 0.0709 - val_loss: 0.0146 - val_mae: 0.0956\n","Epoch 8/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0079 - mae: 0.0707 - val_loss: 0.0142 - val_mae: 0.0941\n","Epoch 9/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0077 - mae: 0.0697 - val_loss: 0.0153 - val_mae: 0.0975\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step\n","****************************************************************************************************\n","Evaluating mean accuracy on test data \n","\n","accuracy for extraversion is 0.9074776977421106\n","accuracy for neuroticism is 0.9035985630303621\n","accuracy for agreeableness is 0.9016911552302785\n","accuracy for conscientiousness is 0.9147098862197504\n","accuracy for openness is 0.9059694184357922\n","mean accuracy for all classes 0.9066893441316587\n"]}]},{"cell_type":"markdown","source":["# Bidirectional LSTM Model"],"metadata":{"id":"6UebjkYtf-B0"}},{"cell_type":"code","source":["from tensorflow.keras.layers import Bidirectional\n","\n","model = Sequential()\n","\n","# Bidirectional LSTM Layer\n","model.add(Bidirectional(LSTM(128, return_sequences=False), input_shape=(10, 768)))\n","model.add(Dropout(0.3))\n","\n","# Fully connected layer\n","model.add(Dense(64, activation='relu'))\n","\n","# Output layer with 5 outputs for class probabilities\n","model.add(Dense(5, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n","\n","\n","history = model.fit(X_train, y_train,\n","                    epochs=50,\n","                    batch_size=32,\n","                    validation_split=0.2,\n","                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)])\n","\n","\n","y_predict =model.predict(X_test)\n","\n","estimate_accuracy(y_predict)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sejGeCyogVj6","executionInfo":{"status":"ok","timestamp":1724087389345,"user_tz":-330,"elapsed":68589,"user":{"displayName":"Ramakrishna Perla","userId":"14162718140622650242"}},"outputId":"7a3f2bf6-ab34-4292-90a0-ecfc5385a375"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 102ms/step - loss: 0.0196 - mae: 0.1098 - val_loss: 0.0151 - val_mae: 0.0984\n","Epoch 2/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - loss: 0.0114 - mae: 0.0855 - val_loss: 0.0133 - val_mae: 0.0927\n","Epoch 3/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 89ms/step - loss: 0.0098 - mae: 0.0791 - val_loss: 0.0134 - val_mae: 0.0927\n","Epoch 4/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - loss: 0.0084 - mae: 0.0726 - val_loss: 0.0135 - val_mae: 0.0927\n","Epoch 5/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - loss: 0.0081 - mae: 0.0715 - val_loss: 0.0146 - val_mae: 0.0963\n","Epoch 6/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 0.0075 - mae: 0.0685 - val_loss: 0.0143 - val_mae: 0.0955\n","Epoch 7/50\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 72ms/step - loss: 0.0070 - mae: 0.0663 - val_loss: 0.0135 - val_mae: 0.0928\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n","****************************************************************************************************\n","Evaluating mean accuracy on test data \n","\n","accuracy for extraversion is 0.9133533767156093\n","accuracy for neuroticism is 0.9085229433104396\n","accuracy for agreeableness is 0.9113950618494834\n","accuracy for conscientiousness is 0.9190791662923485\n","accuracy for openness is 0.9113908315997985\n","mean accuracy for all classes 0.9127482759535359\n"]}]},{"cell_type":"markdown","source":["# Bidirectional LSTM - Experiment 2"],"metadata":{"id":"8od_ujfBn43h"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout, BatchNormalization\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","\n","# Define the model\n","model = Sequential()\n","\n","# Bidirectional LSTM Layer 1\n","model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(10, 768)))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.3))\n","\n","# Bidirectional LSTM Layer 2\n","model.add(Bidirectional(LSTM(64, return_sequences=False)))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.3))\n","\n","# Fully connected layer\n","model.add(Dense(128, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.3))\n","\n","# Output layer with 5 outputs for class probabilities\n","model.add(Dense(5, activation='sigmoid'))\n","\n","# Compile the model with a more sophisticated optimizer\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='mse', metrics=['mae'])\n","\n","# Model summary\n","model.summary()\n","\n","# Callbacks for training\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n","\n","# Train the model\n","history = model.fit(X_train, y_train,\n","                    epochs=100,\n","                    batch_size=32,\n","                    validation_split=0.2,\n","                    callbacks=[early_stopping, reduce_lr])\n","\n","y_predict =model.predict(X_test)\n","\n","estimate_accuracy(y_predict)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"94j8dGdPn7m_","executionInfo":{"status":"ok","timestamp":1724089248573,"user_tz":-330,"elapsed":1702481,"user":{"displayName":"Ramakrishna Perla","userId":"14162718140622650242"}},"outputId":"8b24bfba-c337-4764-b976-8859523f1710"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_10\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m918,528\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │           \u001b[38;5;34m1,024\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m164,352\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m645\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">918,528</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,102,085\u001b[0m (4.20 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,102,085</span> (4.20 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,101,061\u001b[0m (4.20 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,101,061</span> (4.20 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,024\u001b[0m (4.00 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> (4.00 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 149ms/step - loss: 0.0964 - mae: 0.2601 - val_loss: 0.0356 - val_mae: 0.1514 - learning_rate: 1.0000e-04\n","Epoch 2/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 111ms/step - loss: 0.0800 - mae: 0.2349 - val_loss: 0.0388 - val_mae: 0.1569 - learning_rate: 1.0000e-04\n","Epoch 3/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 132ms/step - loss: 0.0733 - mae: 0.2256 - val_loss: 0.0359 - val_mae: 0.1520 - learning_rate: 1.0000e-04\n","Epoch 4/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 135ms/step - loss: 0.0660 - mae: 0.2131 - val_loss: 0.0361 - val_mae: 0.1520 - learning_rate: 1.0000e-04\n","Epoch 5/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 141ms/step - loss: 0.0634 - mae: 0.2081 - val_loss: 0.0372 - val_mae: 0.1536 - learning_rate: 1.0000e-04\n","Epoch 6/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 142ms/step - loss: 0.0594 - mae: 0.2013 - val_loss: 0.0359 - val_mae: 0.1511 - learning_rate: 1.0000e-04\n","Epoch 7/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 153ms/step - loss: 0.0551 - mae: 0.1929 - val_loss: 0.0343 - val_mae: 0.1480 - learning_rate: 5.0000e-05\n","Epoch 8/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 156ms/step - loss: 0.0551 - mae: 0.1933 - val_loss: 0.0337 - val_mae: 0.1476 - learning_rate: 5.0000e-05\n","Epoch 9/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 106ms/step - loss: 0.0521 - mae: 0.1878 - val_loss: 0.0325 - val_mae: 0.1450 - learning_rate: 5.0000e-05\n","Epoch 10/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 130ms/step - loss: 0.0518 - mae: 0.1867 - val_loss: 0.0311 - val_mae: 0.1413 - learning_rate: 5.0000e-05\n","Epoch 11/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 134ms/step - loss: 0.0495 - mae: 0.1824 - val_loss: 0.0304 - val_mae: 0.1398 - learning_rate: 5.0000e-05\n","Epoch 12/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - loss: 0.0486 - mae: 0.1797 - val_loss: 0.0293 - val_mae: 0.1368 - learning_rate: 5.0000e-05\n","Epoch 13/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 130ms/step - loss: 0.0472 - mae: 0.1773 - val_loss: 0.0286 - val_mae: 0.1352 - learning_rate: 5.0000e-05\n","Epoch 14/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 163ms/step - loss: 0.0468 - mae: 0.1770 - val_loss: 0.0282 - val_mae: 0.1345 - learning_rate: 5.0000e-05\n","Epoch 15/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 115ms/step - loss: 0.0448 - mae: 0.1731 - val_loss: 0.0273 - val_mae: 0.1323 - learning_rate: 5.0000e-05\n","Epoch 16/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 134ms/step - loss: 0.0431 - mae: 0.1687 - val_loss: 0.0269 - val_mae: 0.1309 - learning_rate: 5.0000e-05\n","Epoch 17/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - loss: 0.0431 - mae: 0.1689 - val_loss: 0.0263 - val_mae: 0.1292 - learning_rate: 5.0000e-05\n","Epoch 18/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 135ms/step - loss: 0.0439 - mae: 0.1708 - val_loss: 0.0258 - val_mae: 0.1281 - learning_rate: 5.0000e-05\n","Epoch 19/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 117ms/step - loss: 0.0416 - mae: 0.1657 - val_loss: 0.0256 - val_mae: 0.1273 - learning_rate: 5.0000e-05\n","Epoch 20/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - loss: 0.0409 - mae: 0.1650 - val_loss: 0.0252 - val_mae: 0.1260 - learning_rate: 5.0000e-05\n","Epoch 21/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 129ms/step - loss: 0.0401 - mae: 0.1625 - val_loss: 0.0246 - val_mae: 0.1249 - learning_rate: 5.0000e-05\n","Epoch 22/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 111ms/step - loss: 0.0384 - mae: 0.1596 - val_loss: 0.0240 - val_mae: 0.1232 - learning_rate: 5.0000e-05\n","Epoch 23/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 138ms/step - loss: 0.0379 - mae: 0.1581 - val_loss: 0.0234 - val_mae: 0.1217 - learning_rate: 5.0000e-05\n","Epoch 24/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 114ms/step - loss: 0.0370 - mae: 0.1563 - val_loss: 0.0225 - val_mae: 0.1189 - learning_rate: 5.0000e-05\n","Epoch 25/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 133ms/step - loss: 0.0357 - mae: 0.1534 - val_loss: 0.0222 - val_mae: 0.1181 - learning_rate: 5.0000e-05\n","Epoch 26/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 115ms/step - loss: 0.0359 - mae: 0.1538 - val_loss: 0.0223 - val_mae: 0.1186 - learning_rate: 5.0000e-05\n","Epoch 27/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 140ms/step - loss: 0.0347 - mae: 0.1508 - val_loss: 0.0219 - val_mae: 0.1174 - learning_rate: 5.0000e-05\n","Epoch 28/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 125ms/step - loss: 0.0338 - mae: 0.1478 - val_loss: 0.0218 - val_mae: 0.1171 - learning_rate: 5.0000e-05\n","Epoch 29/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - loss: 0.0329 - mae: 0.1467 - val_loss: 0.0212 - val_mae: 0.1158 - learning_rate: 5.0000e-05\n","Epoch 30/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 139ms/step - loss: 0.0334 - mae: 0.1472 - val_loss: 0.0211 - val_mae: 0.1150 - learning_rate: 5.0000e-05\n","Epoch 31/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 137ms/step - loss: 0.0316 - mae: 0.1440 - val_loss: 0.0208 - val_mae: 0.1141 - learning_rate: 5.0000e-05\n","Epoch 32/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 0.0307 - mae: 0.1408 - val_loss: 0.0207 - val_mae: 0.1145 - learning_rate: 5.0000e-05\n","Epoch 33/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 133ms/step - loss: 0.0314 - mae: 0.1426 - val_loss: 0.0203 - val_mae: 0.1132 - learning_rate: 5.0000e-05\n","Epoch 34/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 112ms/step - loss: 0.0302 - mae: 0.1389 - val_loss: 0.0201 - val_mae: 0.1129 - learning_rate: 5.0000e-05\n","Epoch 35/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 128ms/step - loss: 0.0295 - mae: 0.1377 - val_loss: 0.0198 - val_mae: 0.1119 - learning_rate: 5.0000e-05\n","Epoch 36/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 140ms/step - loss: 0.0293 - mae: 0.1374 - val_loss: 0.0195 - val_mae: 0.1107 - learning_rate: 5.0000e-05\n","Epoch 37/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - loss: 0.0278 - mae: 0.1336 - val_loss: 0.0191 - val_mae: 0.1096 - learning_rate: 5.0000e-05\n","Epoch 38/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 141ms/step - loss: 0.0280 - mae: 0.1345 - val_loss: 0.0190 - val_mae: 0.1088 - learning_rate: 5.0000e-05\n","Epoch 39/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 131ms/step - loss: 0.0270 - mae: 0.1315 - val_loss: 0.0188 - val_mae: 0.1084 - learning_rate: 5.0000e-05\n","Epoch 40/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 0.0271 - mae: 0.1326 - val_loss: 0.0190 - val_mae: 0.1092 - learning_rate: 5.0000e-05\n","Epoch 41/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 141ms/step - loss: 0.0262 - mae: 0.1301 - val_loss: 0.0188 - val_mae: 0.1085 - learning_rate: 5.0000e-05\n","Epoch 42/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 129ms/step - loss: 0.0251 - mae: 0.1269 - val_loss: 0.0184 - val_mae: 0.1075 - learning_rate: 5.0000e-05\n","Epoch 43/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 129ms/step - loss: 0.0249 - mae: 0.1257 - val_loss: 0.0183 - val_mae: 0.1076 - learning_rate: 5.0000e-05\n","Epoch 44/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 133ms/step - loss: 0.0251 - mae: 0.1270 - val_loss: 0.0180 - val_mae: 0.1068 - learning_rate: 5.0000e-05\n","Epoch 45/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 0.0240 - mae: 0.1236 - val_loss: 0.0180 - val_mae: 0.1068 - learning_rate: 5.0000e-05\n","Epoch 46/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 0.0233 - mae: 0.1221 - val_loss: 0.0179 - val_mae: 0.1063 - learning_rate: 5.0000e-05\n","Epoch 47/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 131ms/step - loss: 0.0233 - mae: 0.1223 - val_loss: 0.0179 - val_mae: 0.1064 - learning_rate: 5.0000e-05\n","Epoch 48/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - loss: 0.0218 - mae: 0.1189 - val_loss: 0.0178 - val_mae: 0.1058 - learning_rate: 5.0000e-05\n","Epoch 49/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 141ms/step - loss: 0.0221 - mae: 0.1184 - val_loss: 0.0174 - val_mae: 0.1047 - learning_rate: 5.0000e-05\n","Epoch 50/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 105ms/step - loss: 0.0223 - mae: 0.1197 - val_loss: 0.0173 - val_mae: 0.1045 - learning_rate: 5.0000e-05\n","Epoch 51/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 153ms/step - loss: 0.0215 - mae: 0.1169 - val_loss: 0.0171 - val_mae: 0.1039 - learning_rate: 5.0000e-05\n","Epoch 52/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 125ms/step - loss: 0.0210 - mae: 0.1157 - val_loss: 0.0170 - val_mae: 0.1035 - learning_rate: 5.0000e-05\n","Epoch 53/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 130ms/step - loss: 0.0201 - mae: 0.1134 - val_loss: 0.0166 - val_mae: 0.1023 - learning_rate: 5.0000e-05\n","Epoch 54/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 103ms/step - loss: 0.0203 - mae: 0.1133 - val_loss: 0.0166 - val_mae: 0.1023 - learning_rate: 5.0000e-05\n","Epoch 55/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 123ms/step - loss: 0.0200 - mae: 0.1124 - val_loss: 0.0165 - val_mae: 0.1019 - learning_rate: 5.0000e-05\n","Epoch 56/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - loss: 0.0194 - mae: 0.1109 - val_loss: 0.0164 - val_mae: 0.1015 - learning_rate: 5.0000e-05\n","Epoch 57/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 129ms/step - loss: 0.0194 - mae: 0.1107 - val_loss: 0.0163 - val_mae: 0.1010 - learning_rate: 5.0000e-05\n","Epoch 58/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 111ms/step - loss: 0.0189 - mae: 0.1099 - val_loss: 0.0162 - val_mae: 0.1007 - learning_rate: 5.0000e-05\n","Epoch 59/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 0.0178 - mae: 0.1068 - val_loss: 0.0162 - val_mae: 0.1010 - learning_rate: 5.0000e-05\n","Epoch 60/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 130ms/step - loss: 0.0175 - mae: 0.1048 - val_loss: 0.0160 - val_mae: 0.1002 - learning_rate: 5.0000e-05\n","Epoch 61/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 128ms/step - loss: 0.0179 - mae: 0.1065 - val_loss: 0.0159 - val_mae: 0.1001 - learning_rate: 5.0000e-05\n","Epoch 62/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - loss: 0.0178 - mae: 0.1061 - val_loss: 0.0158 - val_mae: 0.1000 - learning_rate: 5.0000e-05\n","Epoch 63/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - loss: 0.0175 - mae: 0.1053 - val_loss: 0.0156 - val_mae: 0.0992 - learning_rate: 5.0000e-05\n","Epoch 64/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 133ms/step - loss: 0.0164 - mae: 0.1023 - val_loss: 0.0156 - val_mae: 0.0993 - learning_rate: 5.0000e-05\n","Epoch 65/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 137ms/step - loss: 0.0168 - mae: 0.1032 - val_loss: 0.0160 - val_mae: 0.1003 - learning_rate: 5.0000e-05\n","Epoch 66/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - loss: 0.0162 - mae: 0.1013 - val_loss: 0.0157 - val_mae: 0.0996 - learning_rate: 5.0000e-05\n","Epoch 67/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 132ms/step - loss: 0.0156 - mae: 0.0994 - val_loss: 0.0156 - val_mae: 0.0992 - learning_rate: 5.0000e-05\n","Epoch 68/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - loss: 0.0156 - mae: 0.0987 - val_loss: 0.0153 - val_mae: 0.0981 - learning_rate: 5.0000e-05\n","Epoch 69/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 135ms/step - loss: 0.0150 - mae: 0.0972 - val_loss: 0.0153 - val_mae: 0.0980 - learning_rate: 5.0000e-05\n","Epoch 70/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 129ms/step - loss: 0.0149 - mae: 0.0964 - val_loss: 0.0154 - val_mae: 0.0982 - learning_rate: 5.0000e-05\n","Epoch 71/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 137ms/step - loss: 0.0145 - mae: 0.0953 - val_loss: 0.0155 - val_mae: 0.0985 - learning_rate: 5.0000e-05\n","Epoch 72/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - loss: 0.0143 - mae: 0.0950 - val_loss: 0.0152 - val_mae: 0.0975 - learning_rate: 5.0000e-05\n","Epoch 73/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 0.0135 - mae: 0.0923 - val_loss: 0.0152 - val_mae: 0.0976 - learning_rate: 5.0000e-05\n","Epoch 74/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 131ms/step - loss: 0.0141 - mae: 0.0939 - val_loss: 0.0150 - val_mae: 0.0966 - learning_rate: 5.0000e-05\n","Epoch 75/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 160ms/step - loss: 0.0136 - mae: 0.0925 - val_loss: 0.0150 - val_mae: 0.0967 - learning_rate: 5.0000e-05\n","Epoch 76/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 128ms/step - loss: 0.0136 - mae: 0.0924 - val_loss: 0.0149 - val_mae: 0.0966 - learning_rate: 5.0000e-05\n","Epoch 77/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 118ms/step - loss: 0.0133 - mae: 0.0911 - val_loss: 0.0148 - val_mae: 0.0961 - learning_rate: 5.0000e-05\n","Epoch 78/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 132ms/step - loss: 0.0128 - mae: 0.0897 - val_loss: 0.0149 - val_mae: 0.0968 - learning_rate: 5.0000e-05\n","Epoch 79/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 101ms/step - loss: 0.0125 - mae: 0.0883 - val_loss: 0.0148 - val_mae: 0.0959 - learning_rate: 5.0000e-05\n","Epoch 80/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 127ms/step - loss: 0.0125 - mae: 0.0886 - val_loss: 0.0148 - val_mae: 0.0964 - learning_rate: 5.0000e-05\n","Epoch 81/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 176ms/step - loss: 0.0126 - mae: 0.0886 - val_loss: 0.0147 - val_mae: 0.0959 - learning_rate: 5.0000e-05\n","Epoch 82/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 128ms/step - loss: 0.0122 - mae: 0.0878 - val_loss: 0.0146 - val_mae: 0.0956 - learning_rate: 5.0000e-05\n","Epoch 83/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - loss: 0.0117 - mae: 0.0861 - val_loss: 0.0147 - val_mae: 0.0959 - learning_rate: 5.0000e-05\n","Epoch 84/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 0.0118 - mae: 0.0861 - val_loss: 0.0147 - val_mae: 0.0960 - learning_rate: 5.0000e-05\n","Epoch 85/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - loss: 0.0115 - mae: 0.0849 - val_loss: 0.0147 - val_mae: 0.0959 - learning_rate: 5.0000e-05\n","Epoch 86/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 159ms/step - loss: 0.0109 - mae: 0.0828 - val_loss: 0.0147 - val_mae: 0.0958 - learning_rate: 5.0000e-05\n","Epoch 87/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 130ms/step - loss: 0.0112 - mae: 0.0839 - val_loss: 0.0146 - val_mae: 0.0956 - learning_rate: 5.0000e-05\n","Epoch 88/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 0.0109 - mae: 0.0828 - val_loss: 0.0145 - val_mae: 0.0953 - learning_rate: 2.5000e-05\n","Epoch 89/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - loss: 0.0110 - mae: 0.0834 - val_loss: 0.0146 - val_mae: 0.0955 - learning_rate: 2.5000e-05\n","Epoch 90/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - loss: 0.0105 - mae: 0.0811 - val_loss: 0.0145 - val_mae: 0.0953 - learning_rate: 2.5000e-05\n","Epoch 91/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 125ms/step - loss: 0.0108 - mae: 0.0820 - val_loss: 0.0146 - val_mae: 0.0955 - learning_rate: 2.5000e-05\n","Epoch 92/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - loss: 0.0106 - mae: 0.0824 - val_loss: 0.0145 - val_mae: 0.0951 - learning_rate: 2.5000e-05\n","Epoch 93/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 0.0106 - mae: 0.0817 - val_loss: 0.0145 - val_mae: 0.0953 - learning_rate: 2.5000e-05\n","Epoch 94/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 131ms/step - loss: 0.0105 - mae: 0.0812 - val_loss: 0.0145 - val_mae: 0.0953 - learning_rate: 1.2500e-05\n","Epoch 95/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 108ms/step - loss: 0.0104 - mae: 0.0811 - val_loss: 0.0146 - val_mae: 0.0954 - learning_rate: 1.2500e-05\n","Epoch 96/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 129ms/step - loss: 0.0102 - mae: 0.0801 - val_loss: 0.0145 - val_mae: 0.0952 - learning_rate: 1.2500e-05\n","Epoch 97/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 142ms/step - loss: 0.0106 - mae: 0.0810 - val_loss: 0.0145 - val_mae: 0.0951 - learning_rate: 1.2500e-05\n","Epoch 98/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 154ms/step - loss: 0.0100 - mae: 0.0792 - val_loss: 0.0145 - val_mae: 0.0950 - learning_rate: 1.2500e-05\n","Epoch 99/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 134ms/step - loss: 0.0106 - mae: 0.0819 - val_loss: 0.0145 - val_mae: 0.0951 - learning_rate: 6.2500e-06\n","Epoch 100/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 117ms/step - loss: 0.0102 - mae: 0.0802 - val_loss: 0.0144 - val_mae: 0.0948 - learning_rate: 6.2500e-06\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step\n","****************************************************************************************************\n","Evaluating mean accuracy on test data \n","\n","accuracy for extraversion is 0.908544929576707\n","accuracy for neuroticism is 0.9034379344942669\n","accuracy for agreeableness is 0.9061770304178635\n","accuracy for conscientiousness is 0.9153315402021251\n","accuracy for openness is 0.9069206080559228\n","mean accuracy for all classes 0.908082408549377\n"]}]},{"cell_type":"markdown","source":["# GRU Model"],"metadata":{"id":"Qes3tun5tOok"}},{"cell_type":"code","source":["from tensorflow.keras.layers import GRU\n","\n","model = Sequential()\n","\n","# GRU Layer\n","model.add(GRU(128, input_shape=(10, 768), return_sequences=False))\n","model.add(Dropout(0.3))\n","\n","# Dense Layer\n","model.add(Dense(64, activation='relu'))\n","\n","# Output Layer\n","model.add(Dense(5, activation='sigmoid'))\n","\n","# Compile\n","model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n","\n","\n","# Model summary\n","model.summary()\n","\n","# Callbacks for training\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n","\n","# Train the model\n","history = model.fit(X_train, y_train,\n","                    epochs=100,\n","                    batch_size=32,\n","                    validation_split=0.2,\n","                    callbacks=[early_stopping, reduce_lr])\n","\n","y_predict =model.predict(X_test)\n","\n","estimate_accuracy(y_predict)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Wlxv2CCgtPvS","executionInfo":{"status":"ok","timestamp":1724089717258,"user_tz":-330,"elapsed":100752,"user":{"displayName":"Ramakrishna Perla","userId":"14162718140622650242"}},"outputId":"e8567908-fc22-46af-aeb8-19bf12f69944"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_11\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m344,832\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m325\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">344,832</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m353,413\u001b[0m (1.35 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">353,413</span> (1.35 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m353,413\u001b[0m (1.35 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">353,413</span> (1.35 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 58ms/step - loss: 0.0223 - mae: 0.1184 - val_loss: 0.0140 - val_mae: 0.0948 - learning_rate: 0.0010\n","Epoch 2/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - loss: 0.0127 - mae: 0.0903 - val_loss: 0.0132 - val_mae: 0.0916 - learning_rate: 0.0010\n","Epoch 3/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 65ms/step - loss: 0.0112 - mae: 0.0845 - val_loss: 0.0130 - val_mae: 0.0912 - learning_rate: 0.0010\n","Epoch 4/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 0.0101 - mae: 0.0799 - val_loss: 0.0128 - val_mae: 0.0904 - learning_rate: 0.0010\n","Epoch 5/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 60ms/step - loss: 0.0095 - mae: 0.0774 - val_loss: 0.0127 - val_mae: 0.0901 - learning_rate: 0.0010\n","Epoch 6/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - loss: 0.0085 - mae: 0.0730 - val_loss: 0.0130 - val_mae: 0.0910 - learning_rate: 0.0010\n","Epoch 7/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - loss: 0.0084 - mae: 0.0727 - val_loss: 0.0141 - val_mae: 0.0938 - learning_rate: 0.0010\n","Epoch 8/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - loss: 0.0080 - mae: 0.0709 - val_loss: 0.0131 - val_mae: 0.0911 - learning_rate: 0.0010\n","Epoch 9/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0075 - mae: 0.0684 - val_loss: 0.0133 - val_mae: 0.0917 - learning_rate: 0.0010\n","Epoch 10/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - loss: 0.0067 - mae: 0.0654 - val_loss: 0.0133 - val_mae: 0.0918 - learning_rate: 5.0000e-04\n","Epoch 11/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - loss: 0.0063 - mae: 0.0629 - val_loss: 0.0134 - val_mae: 0.0916 - learning_rate: 5.0000e-04\n","Epoch 12/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - loss: 0.0063 - mae: 0.0625 - val_loss: 0.0132 - val_mae: 0.0914 - learning_rate: 5.0000e-04\n","Epoch 13/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0058 - mae: 0.0607 - val_loss: 0.0133 - val_mae: 0.0920 - learning_rate: 5.0000e-04\n","Epoch 14/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - loss: 0.0059 - mae: 0.0610 - val_loss: 0.0136 - val_mae: 0.0925 - learning_rate: 5.0000e-04\n","Epoch 15/100\n","\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - loss: 0.0055 - mae: 0.0585 - val_loss: 0.0135 - val_mae: 0.0923 - learning_rate: 2.5000e-04\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n","****************************************************************************************************\n","Evaluating mean accuracy on test data \n","\n","accuracy for extraversion is 0.911515787338542\n","accuracy for neuroticism is 0.9067548668583234\n","accuracy for agreeableness is 0.9114139176476952\n","accuracy for conscientiousness is 0.9186171205469127\n","accuracy for openness is 0.9107564763733083\n","mean accuracy for all classes 0.9118116337529564\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1s3rQ3u6XdQQKCozmhpX8h32Dddc9H4CO","timestamp":1724083630271},{"file_id":"1iNaUOh9sjn0wTt9IULNWn1yqln4zy04x","timestamp":1724042391630},{"file_id":"1v_Pt3QCnTpJWiW38b4zdWdBMt9mhj8y1","timestamp":1723700083174},{"file_id":"1Ncmd9CdWzZLNGI-4OXFfZyT1UjwFzQ1X","timestamp":1723617592335},{"file_id":"1eNSG9WWu-_-ahp6R8tDWJrNVimm0XCu3","timestamp":1723609273172}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7dca3359b4f643588dae84bddd3b3317":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ac59759f851a497abac162bc8c66eb20","IPY_MODEL_b930956c9b554687a23fe735e6517e2d","IPY_MODEL_18a6870a37ca42a8a0acafc895ebf095"],"layout":"IPY_MODEL_7f5f85da853c4fc3b21e38fc53d58bc8"}},"ac59759f851a497abac162bc8c66eb20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8011d68b1e504a958e01b1199e2c7dc5","placeholder":"​","style":"IPY_MODEL_c22012026fa04f438c7dc79809f983f8","value":"100%"}},"b930956c9b554687a23fe735e6517e2d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b18ec9819cfa4b4d82e576cb00cc2354","max":362,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b18b5d7f7214ba3a733957da1f767bb","value":362}},"18a6870a37ca42a8a0acafc895ebf095":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_152f05a8b5dc49eaa199586508333512","placeholder":"​","style":"IPY_MODEL_3b519d4e34ca4997983c7f11eabd51ae","value":" 362/362 [00:21&lt;00:00, 29.23it/s]"}},"7f5f85da853c4fc3b21e38fc53d58bc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8011d68b1e504a958e01b1199e2c7dc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c22012026fa04f438c7dc79809f983f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b18ec9819cfa4b4d82e576cb00cc2354":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b18b5d7f7214ba3a733957da1f767bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"152f05a8b5dc49eaa199586508333512":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b519d4e34ca4997983c7f11eabd51ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72ae9cd15d744d4db1c6c2f869114bbf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a5a37f64df7f4648a75996703e514359","IPY_MODEL_61e6e2e2e1c14e6d9498f09b63d97c1e","IPY_MODEL_113001b09f5c4e5fa5ec7ee8069793d4"],"layout":"IPY_MODEL_b01b4ebf918048e89ab0f876ced2cb52"}},"a5a37f64df7f4648a75996703e514359":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58efc092771749fa866cb034998dd1bc","placeholder":"​","style":"IPY_MODEL_04e1428161c64142929186bf8d4d7acd","value":"100%"}},"61e6e2e2e1c14e6d9498f09b63d97c1e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c4898d534194f2f9535569eb3416833","max":200,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84afd341550e48fb80de3dffdb827246","value":200}},"113001b09f5c4e5fa5ec7ee8069793d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57836dcd081a4a12a109f33f02b52479","placeholder":"​","style":"IPY_MODEL_1574f7c5ac76492ab2ce559f4ae229cf","value":" 200/200 [00:04&lt;00:00, 125.31it/s]"}},"b01b4ebf918048e89ab0f876ced2cb52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58efc092771749fa866cb034998dd1bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04e1428161c64142929186bf8d4d7acd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c4898d534194f2f9535569eb3416833":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84afd341550e48fb80de3dffdb827246":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"57836dcd081a4a12a109f33f02b52479":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1574f7c5ac76492ab2ce559f4ae229cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}